---
title: "Bulk Uploading Mammal Data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Bulk Uploading Mammal Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

The purpose of the `bulkUploader` package is to help data managers to bring their data into the [Neotoma Paleoecology Database](https://neotomadb.org).  Neotoma is a highly structured database that contains information on a large number of data types, including diatoms, ostracodes, pollen and mammal fossils.

Neotoma is really a "database of databases", and contains X constituent databases.  To help data managers include their data in Neotoma, we have wrapped Neotoma package functions around tools to help manage, validate and upload their data into Neotoma.

## Managing your Data

The easiest data to enter into Neotoma is the publication data and contact data.  From a given database, or data resource, check 

### Publication Data

However your publication data is organized, it must be aligned with Neotoma's so that it can be included in the database.  The Neotoma `publications` table uses the following fields:

```{r setup, result='hide'}
devtools::install_github('NeotomaDB/bulkuploader')
library(bulkUploader)
devtools::install_github('NeotomaDB/neotoma2') 
library(neotoma2)

```

```{r}

results <- data.frame(score=rep(NA, nrow(pavelacsv)), delta = NA)
outputs <- list()

for (i in 1:nrow(pavelacsv)) {
  container = ifelse(is.na(pavelacsv$journal[i]),
                     pavelacsv$booktitle[i],
                     pavelacsv$journal[i]) # if first element is 'TRUE', then this returns a number corresponding to the level index for the book title' if first element is 'FALSE', then this returns a number corresponding to the level index for the journal
  if(is.na(container)) {
    message("Row ", i, " is missing a title.")
  } else {
    outputs[[i]] <- scrape_dois(title = pavelacsv$articletitle[i],
                        year = pavelacsv$year[i])
    if (length(outputs[[i]]) > 0) {
      results$score[i] <- outputs[[i]][[1]]$score
      if (length(outputs[[i]]) > 1) {
        results$delta[i] <- outputs[[i]][[1]]$score - outputs[[i]][[2]]$score
      }
      message("Tested article ", i)
    } else {
      message("Couldn't get a match for ", i)
    }
  }
}
```

From this output we have a `list` object called `outputs`, with a length equal to the number of publications in the original data file.  We also have a `data.frame` called `results` with columns `score` and `delta`.

The `score` gives the approximate match strength to a publication in CrossRef.  The `delta` lets us know what the score of the next closest match is.  Because we need to work with the CrossRef API in a reasonable way, this matching tends to be slow.

Once this script runs we then have a set of publications for the constituent database, and for each described publication we have 0 or more potential matches.  To generate a simple match we want to create some form of citation.  We can do this using the very simple helper function `makeCite()`.


```{r reviewPubs}

pavelacites <- makeCite(pavelacsv$year, 
                     pavelacsv$articletitle, 
                     pavelacsv$journal)

crossCites <- outputs %>% map(cr_to_neotoma) # Note: this section may not work until I can get neotoma2 to load
```

